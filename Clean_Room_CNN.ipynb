{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Room CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries \n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib as plt\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras import models\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "%matplotlib inline\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Directory and Allocate Images__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to amass our clean room data we used the AED20k Dataset of online images that had prelabeled scenes. The scenes we decided to look at specifically were tagged \"kitchen\", \"living room\", and \"bedroom\". Bathrooms we determined were not necessary as they should be cleaned regardless of thier perceived cleanliness for obvious hygene purposes. In total we were able to download about 2000 images of clean rooms but the real challenge was going to be collecting dirty images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create objects for our images in our train sets\n",
    "train_clean_room_dir = '/Users/AlexGaujean/Downloads/data/train_folder/train_clean_room'\n",
    "train_dirty_room_dir = '/Users/AlexGaujean/Downloads/data/train_folder/train_dirty_room'\n",
    "\n",
    "\n",
    "#create directory objects for our items in our validation and test sets\n",
    "validation_clean_room_dir = '/Users/AlexGaujean/Downloads/data/validation_folder/val_clean_room'\n",
    "validation_dirty_room_dir = '/Users/AlexGaujean/Downloads/data/validation_folder/val_dirty_room'\n",
    "test_clean_room_dir = '/Users/AlexGaujean/Downloads/data/test_folder/test_clean_room'\n",
    "test_dirty_room_dir = '/Users/AlexGaujean/Downloads/data/test_folder/test_dirty_room'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create  variables that contain our list of clean and dirty photos\n",
    "train_imgs_clean = [file for file in os.listdir(train_clean_room_dir) if file.endswith('.jpg')]\n",
    "val_imgs_clean = [file for file in os.listdir(validation_clean_room_dir) if file.endswith('.jpg')]\n",
    "test_imgs_clean = [file for file in os.listdir(test_clean_room_dir) if file.endswith('.jpg')]\n",
    "\n",
    "\n",
    "train_imgs_dirty = [file for file in os.listdir(train_dirty_room_dir) if file.endswith('.jpg')]\n",
    "val_imgs_dirty = [file for file in os.listdir(validation_dirty_room_dir) if file.endswith('.jpg')]\n",
    "test_imgs_dirty = [file for file in os.listdir(test_dirty_room_dir) if file.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672 train images\n",
      "363 validation images\n",
      "390 test images\n"
     ]
    }
   ],
   "source": [
    "#examine the size of each of our train and test set images for our clean data and set up variables to use later\n",
    "batch_size_train = len(train_imgs_clean) + len(train_imgs_dirty) \n",
    "batch_size_val = len(val_imgs_clean) + len(val_imgs_dirty) \n",
    "batch_size_test = len(test_imgs_clean) +len(test_imgs_dirty) \n",
    "\n",
    "print(batch_size_train, 'train images') \n",
    "print(batch_size_val, 'validation images') \n",
    "print(batch_size_test, 'test images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish directories for all of our train, test, and validation data \n",
    "train_dir = '/Users/AlexGaujean/Downloads/data/train_folder'\n",
    "val_dir = '/Users/AlexGaujean/Downloads/data/validation_folder'\n",
    "test_dir = '/Users/AlexGaujean/Downloads/data/test_folder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Webscraping for Dirty Rooms:__ Run this JavaScript in the chrome console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this Javascript code in the chrome console# \n",
    "// pull down jquery into the JavaScript console\n",
    "var script = document.createElement('script');\n",
    "script.src = \"https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js\";\n",
    "document.getElementsByTagName('head')[0].appendChild(script);\n",
    "\n",
    "\n",
    "\n",
    "// grab the URLs\n",
    "var urls = $('.rg_di .rg_meta').map(function() { return JSON.parse($(this).text()).ou; });\n",
    "\n",
    "\n",
    "\n",
    "// write the URls to file (one per line)\n",
    "var textToSave = urls.toArray().join('\\n');\n",
    "var hiddenElement = document.createElement('a');\n",
    "hiddenElement.href = 'data:attachment/text,' + encodeURI(textToSave);\n",
    "hiddenElement.target = '_blank';\n",
    "hiddenElement.download = 'urls.txt';\n",
    "hiddenElement.click();\n",
    "\n",
    "#run this code in the chrome console# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine txt files\n",
    "filenames = ['dirty_bedroom_urls.txt','dirty_kitchen_urls.txt','disorganized_room_urls.txt',\n",
    "             'messy_bedroom_urls.txt','messy_kitchen_urls.txt','messy_living_room_urls.txt',\n",
    "            'messy_room_urls.txt','not_clean_bedroom_urls.txt','slightly_messy_rooms_urls.txt']\n",
    "with open('messy_rooms.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that different queries does not leave us with identical images by removing duplicate urls\n",
    "\n",
    "file = open('messy_rooms.txt', 'r')\n",
    "\n",
    "lines_seen = set() # holds lines already seen\n",
    "outfile = open('messy_rooms_no_duplicates.txt', \"w\")\n",
    "for line in open('messy_rooms.txt', \"r\"):\n",
    "    if line not in lines_seen: # not a duplicate\n",
    "        outfile.write(line)\n",
    "        lines_seen.add(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download images from url txt file\n",
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import requests\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-u\", \"--urls\", required=True,\n",
    "help=\"messy_rooms_no_duplicates.txt\")\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "help=\"images\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# grab the list of URLs from the input file, then initialize the\n",
    "# total number of images downloaded thus far\n",
    "rows = open(args[\"urls\"]).read().strip().split(\"\\n\")\n",
    "total = 0\n",
    "\n",
    "%tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scale and Normalize Images and Create Datasets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary python libraries\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1673 images belonging to 2 classes.\n",
      "Found 390 images belonging to 2 classes.\n",
      "Found 363 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#get all the data in the directory split/test and reshape them using ImageDataGenerator from keras\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_dir, \n",
    "        target_size=(64, 64), batch_size= batch_size_train)\n",
    "#get all the data in the test directory adn reshape them to 64X64 pixel size\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_dir, \n",
    "        target_size=(64, 64), batch_size = batch_size_test)  \n",
    "\n",
    "# get all the data in the directory split/validation (363 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_dir, \n",
    "        target_size=(64, 64), batch_size = batch_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AlexGaujean/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:768: UserWarning: Possibly corrupt EXIF data.  Expecting to read 12 bytes but only got 10. Skipping tag 42037\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/AlexGaujean/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:768: UserWarning: Possibly corrupt EXIF data.  Expecting to read 12 bytes but only got 10. Skipping tag 42037\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/AlexGaujean/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:768: UserWarning: Possibly corrupt EXIF data.  Expecting to read 12 bytes but only got 10. Skipping tag 42037\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    }
   ],
   "source": [
    "# create our image datasets and corresponding labels for our train, validation and test sets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape our labels so that it is either a 0 for dirty rooms, or 1 for clean rooms \n",
    "train_y = np.reshape(train_labels[:,0], (batch_size_train,1))\n",
    "test_y = np.reshape(test_labels[:,0], (batch_size_test,1))\n",
    "val_y = np.reshape(val_labels[:,0], (batch_size_val,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1A384E0860>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to make sure the labels correspond to the correct images \n",
    "print(train_y[1412])\n",
    "array_to_img(train_images[1412])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reshape Image Arrays for CNN Use__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1672\n",
      "Number of testing samples: 390\n",
      "Number of validation samples: 363\n",
      "train_images shape: (1672, 64, 64, 3)\n",
      "train_labels shape: (1672, 2)\n",
      "test_images shape: (390, 64, 64, 3)\n",
      "test_labels shape: (390, 2)\n",
      "val_images shape: (363, 64, 64, 3)\n",
      "val_labels shape: (363, 2)\n"
     ]
    }
   ],
   "source": [
    "# Explore our datasets again and print the shape of each of our images to ensure that we converted it properly\n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1672, 12288) = train size\n",
      "(390, 12288) = test size\n",
      "(363, 12288) = val size\n"
     ]
    }
   ],
   "source": [
    "#reshape our train, test, val image data into a single row that can then be used\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape, '= train size')\n",
    "print(test_img.shape, '= test size')  \n",
    "print(val_img.shape, '= val size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Densely Connected Network: Baseline Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try out a number of different models starting with a densely connected network to run as our baseline. In addition, we are going to try CNN's that we have constructed ourselves as well as a number of Transfer Learning methods, specifically VGG16 and ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/AlexGaujean/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#instantiate our model and add our hidden layers\n",
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(15, activation='relu', input_shape=(12288,)))#3 hidden layers\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/AlexGaujean/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1672 samples, validate on 363 samples\n",
      "Epoch 1/100\n",
      "1672/1672 [==============================] - 3s 2ms/step - loss: 0.6869 - acc: 0.5664 - val_loss: 0.6567 - val_acc: 0.7025\n",
      "Epoch 2/100\n",
      "1672/1672 [==============================] - 0s 156us/step - loss: 0.6806 - acc: 0.5700 - val_loss: 0.6431 - val_acc: 0.7107\n",
      "Epoch 3/100\n",
      "1672/1672 [==============================] - 0s 131us/step - loss: 0.6761 - acc: 0.5688 - val_loss: 0.6392 - val_acc: 0.7052\n",
      "Epoch 4/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6737 - acc: 0.5736 - val_loss: 0.6360 - val_acc: 0.7080\n",
      "Epoch 5/100\n",
      "1672/1672 [==============================] - 0s 114us/step - loss: 0.6717 - acc: 0.5736 - val_loss: 0.6331 - val_acc: 0.7080\n",
      "Epoch 6/100\n",
      "1672/1672 [==============================] - 0s 79us/step - loss: 0.6699 - acc: 0.5778 - val_loss: 0.6331 - val_acc: 0.7107\n",
      "Epoch 7/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6682 - acc: 0.5915 - val_loss: 0.6247 - val_acc: 0.7107\n",
      "Epoch 8/100\n",
      "1672/1672 [==============================] - 0s 91us/step - loss: 0.6667 - acc: 0.5772 - val_loss: 0.6366 - val_acc: 0.7190\n",
      "Epoch 9/100\n",
      "1672/1672 [==============================] - 0s 90us/step - loss: 0.6660 - acc: 0.5981 - val_loss: 0.6110 - val_acc: 0.7107\n",
      "Epoch 10/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6682 - acc: 0.5688 - val_loss: 0.6668 - val_acc: 0.6253\n",
      "Epoch 11/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6752 - acc: 0.5927 - val_loss: 0.5991 - val_acc: 0.7080\n",
      "Epoch 12/100\n",
      "1672/1672 [==============================] - 0s 83us/step - loss: 0.6853 - acc: 0.5502 - val_loss: 0.6485 - val_acc: 0.7135\n",
      "Epoch 13/100\n",
      "1672/1672 [==============================] - 0s 89us/step - loss: 0.6672 - acc: 0.6166 - val_loss: 0.6070 - val_acc: 0.7163\n",
      "Epoch 14/100\n",
      "1672/1672 [==============================] - 0s 87us/step - loss: 0.6684 - acc: 0.5682 - val_loss: 0.6605 - val_acc: 0.6391\n",
      "Epoch 15/100\n",
      "1672/1672 [==============================] - 0s 88us/step - loss: 0.6695 - acc: 0.6089 - val_loss: 0.5994 - val_acc: 0.7135\n",
      "Epoch 16/100\n",
      "1672/1672 [==============================] - 0s 95us/step - loss: 0.6786 - acc: 0.5562 - val_loss: 0.6474 - val_acc: 0.7052\n",
      "Epoch 17/100\n",
      "1672/1672 [==============================] - 0s 83us/step - loss: 0.6637 - acc: 0.6256 - val_loss: 0.6038 - val_acc: 0.7135\n",
      "Epoch 18/100\n",
      "1672/1672 [==============================] - 0s 104us/step - loss: 0.6669 - acc: 0.5676 - val_loss: 0.6567 - val_acc: 0.6529\n",
      "Epoch 19/100\n",
      "1672/1672 [==============================] - 0s 89us/step - loss: 0.6652 - acc: 0.6250 - val_loss: 0.5965 - val_acc: 0.7107\n",
      "Epoch 20/100\n",
      "1672/1672 [==============================] - 0s 94us/step - loss: 0.6766 - acc: 0.5586 - val_loss: 0.6517 - val_acc: 0.6694\n",
      "Epoch 21/100\n",
      "1672/1672 [==============================] - 0s 83us/step - loss: 0.6627 - acc: 0.6376 - val_loss: 0.5988 - val_acc: 0.7135\n",
      "Epoch 22/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6680 - acc: 0.5670 - val_loss: 0.6573 - val_acc: 0.6474\n",
      "Epoch 23/100\n",
      "1672/1672 [==============================] - 0s 79us/step - loss: 0.6634 - acc: 0.6220 - val_loss: 0.5952 - val_acc: 0.7135\n",
      "Epoch 24/100\n",
      "1672/1672 [==============================] - 0s 77us/step - loss: 0.6733 - acc: 0.5628 - val_loss: 0.6502 - val_acc: 0.6804\n",
      "Epoch 25/100\n",
      "1672/1672 [==============================] - 0s 91us/step - loss: 0.6597 - acc: 0.6441 - val_loss: 0.5969 - val_acc: 0.7163\n",
      "Epoch 26/100\n",
      "1672/1672 [==============================] - 0s 96us/step - loss: 0.6647 - acc: 0.5688 - val_loss: 0.6548 - val_acc: 0.6419\n",
      "Epoch 27/100\n",
      "1672/1672 [==============================] - 0s 77us/step - loss: 0.6599 - acc: 0.6328 - val_loss: 0.5926 - val_acc: 0.7163\n",
      "Epoch 28/100\n",
      "1672/1672 [==============================] - 0s 81us/step - loss: 0.6703 - acc: 0.5652 - val_loss: 0.6545 - val_acc: 0.6446\n",
      "Epoch 29/100\n",
      "1672/1672 [==============================] - 0s 77us/step - loss: 0.6593 - acc: 0.6322 - val_loss: 0.5934 - val_acc: 0.7135\n",
      "Epoch 30/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6647 - acc: 0.5706 - val_loss: 0.6561 - val_acc: 0.6391\n",
      "Epoch 31/100\n",
      "1672/1672 [==============================] - 0s 105us/step - loss: 0.6588 - acc: 0.6310 - val_loss: 0.5909 - val_acc: 0.7163\n",
      "Epoch 32/100\n",
      "1672/1672 [==============================] - 0s 81us/step - loss: 0.6670 - acc: 0.5682 - val_loss: 0.6545 - val_acc: 0.6419\n",
      "Epoch 33/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6572 - acc: 0.6322 - val_loss: 0.5905 - val_acc: 0.7163\n",
      "Epoch 34/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6632 - acc: 0.5712 - val_loss: 0.6579 - val_acc: 0.6088\n",
      "Epoch 35/100\n",
      "1672/1672 [==============================] - 0s 95us/step - loss: 0.6577 - acc: 0.6292 - val_loss: 0.5878 - val_acc: 0.7163\n",
      "Epoch 36/100\n",
      "1672/1672 [==============================] - 0s 101us/step - loss: 0.6672 - acc: 0.5688 - val_loss: 0.6529 - val_acc: 0.6364\n",
      "Epoch 37/100\n",
      "1672/1672 [==============================] - 0s 84us/step - loss: 0.6552 - acc: 0.6370 - val_loss: 0.5889 - val_acc: 0.7218\n",
      "Epoch 38/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6592 - acc: 0.5778 - val_loss: 0.6587 - val_acc: 0.6061\n",
      "Epoch 39/100\n",
      "1672/1672 [==============================] - 0s 82us/step - loss: 0.6562 - acc: 0.6238 - val_loss: 0.5859 - val_acc: 0.7190\n",
      "Epoch 40/100\n",
      "1672/1672 [==============================] - 0s 94us/step - loss: 0.6632 - acc: 0.5748 - val_loss: 0.6581 - val_acc: 0.6088\n",
      "Epoch 41/100\n",
      "1672/1672 [==============================] - 0s 95us/step - loss: 0.6554 - acc: 0.6268 - val_loss: 0.5858 - val_acc: 0.7218\n",
      "Epoch 42/100\n",
      "1672/1672 [==============================] - 0s 95us/step - loss: 0.6591 - acc: 0.5778 - val_loss: 0.6597 - val_acc: 0.6061\n",
      "Epoch 43/100\n",
      "1672/1672 [==============================] - 0s 85us/step - loss: 0.6550 - acc: 0.6220 - val_loss: 0.5843 - val_acc: 0.7218\n",
      "Epoch 44/100\n",
      "1672/1672 [==============================] - 0s 97us/step - loss: 0.6598 - acc: 0.5778 - val_loss: 0.6601 - val_acc: 0.6088\n",
      "Epoch 45/100\n",
      "1672/1672 [==============================] - 0s 86us/step - loss: 0.6548 - acc: 0.6208 - val_loss: 0.5842 - val_acc: 0.7218\n",
      "Epoch 46/100\n",
      "1672/1672 [==============================] - 0s 91us/step - loss: 0.6553 - acc: 0.5879 - val_loss: 0.6607 - val_acc: 0.6061\n",
      "Epoch 47/100\n",
      "1672/1672 [==============================] - 0s 83us/step - loss: 0.6539 - acc: 0.6172 - val_loss: 0.5823 - val_acc: 0.7190\n",
      "Epoch 48/100\n",
      "1672/1672 [==============================] - 0s 77us/step - loss: 0.6564 - acc: 0.5843 - val_loss: 0.6592 - val_acc: 0.6116\n",
      "Epoch 49/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6529 - acc: 0.6226 - val_loss: 0.5825 - val_acc: 0.7190\n",
      "Epoch 50/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6516 - acc: 0.5903 - val_loss: 0.6561 - val_acc: 0.6061\n",
      "Epoch 51/100\n",
      "1672/1672 [==============================] - 0s 85us/step - loss: 0.6500 - acc: 0.6256 - val_loss: 0.5810 - val_acc: 0.7163\n",
      "Epoch 52/100\n",
      "1672/1672 [==============================] - 0s 101us/step - loss: 0.6512 - acc: 0.5903 - val_loss: 0.6589 - val_acc: 0.6006\n",
      "Epoch 53/100\n",
      "1672/1672 [==============================] - 0s 90us/step - loss: 0.6505 - acc: 0.6244 - val_loss: 0.5798 - val_acc: 0.7190\n",
      "Epoch 54/100\n",
      "1672/1672 [==============================] - 0s 88us/step - loss: 0.6512 - acc: 0.5921 - val_loss: 0.6595 - val_acc: 0.6088\n",
      "Epoch 55/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6501 - acc: 0.6268 - val_loss: 0.5789 - val_acc: 0.7190\n",
      "Epoch 56/100\n",
      "1672/1672 [==============================] - 0s 111us/step - loss: 0.6506 - acc: 0.5933 - val_loss: 0.6589 - val_acc: 0.6061\n",
      "Epoch 57/100\n",
      "1672/1672 [==============================] - 0s 84us/step - loss: 0.6491 - acc: 0.6262 - val_loss: 0.5785 - val_acc: 0.7190\n",
      "Epoch 58/100\n",
      "1672/1672 [==============================] - 0s 75us/step - loss: 0.6490 - acc: 0.5933 - val_loss: 0.6591 - val_acc: 0.6088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "1672/1672 [==============================] - 0s 79us/step - loss: 0.6486 - acc: 0.6274 - val_loss: 0.5780 - val_acc: 0.7218\n",
      "Epoch 60/100\n",
      "1672/1672 [==============================] - 0s 80us/step - loss: 0.6472 - acc: 0.5945 - val_loss: 0.6571 - val_acc: 0.6088\n",
      "Epoch 61/100\n",
      "1672/1672 [==============================] - 0s 79us/step - loss: 0.6467 - acc: 0.6274 - val_loss: 0.5775 - val_acc: 0.7190\n",
      "Epoch 62/100\n",
      "1672/1672 [==============================] - 0s 77us/step - loss: 0.6450 - acc: 0.5993 - val_loss: 0.6565 - val_acc: 0.6088\n",
      "Epoch 63/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6456 - acc: 0.6322 - val_loss: 0.5763 - val_acc: 0.7190\n",
      "Epoch 64/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6448 - acc: 0.5987 - val_loss: 0.6559 - val_acc: 0.6143\n",
      "Epoch 65/100\n",
      "1672/1672 [==============================] - 0s 85us/step - loss: 0.6446 - acc: 0.6334 - val_loss: 0.5756 - val_acc: 0.7190\n",
      "Epoch 66/100\n",
      "1672/1672 [==============================] - 0s 99us/step - loss: 0.6434 - acc: 0.6017 - val_loss: 0.6556 - val_acc: 0.6116\n",
      "Epoch 67/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6438 - acc: 0.6334 - val_loss: 0.5750 - val_acc: 0.7190\n",
      "Epoch 68/100\n",
      "1672/1672 [==============================] - 0s 79us/step - loss: 0.6426 - acc: 0.6029 - val_loss: 0.6551 - val_acc: 0.6171\n",
      "Epoch 69/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6426 - acc: 0.6364 - val_loss: 0.5748 - val_acc: 0.7135\n",
      "Epoch 70/100\n",
      "1672/1672 [==============================] - 0s 107us/step - loss: 0.6395 - acc: 0.6065 - val_loss: 0.6515 - val_acc: 0.6226\n",
      "Epoch 71/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6403 - acc: 0.6388 - val_loss: 0.5741 - val_acc: 0.7135\n",
      "Epoch 72/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6386 - acc: 0.6077 - val_loss: 0.6514 - val_acc: 0.6088\n",
      "Epoch 73/100\n",
      "1672/1672 [==============================] - 0s 75us/step - loss: 0.6393 - acc: 0.6382 - val_loss: 0.5734 - val_acc: 0.7163\n",
      "Epoch 74/100\n",
      "1672/1672 [==============================] - 0s 74us/step - loss: 0.6373 - acc: 0.6124 - val_loss: 0.6517 - val_acc: 0.6198\n",
      "Epoch 75/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6388 - acc: 0.6358 - val_loss: 0.5722 - val_acc: 0.7135\n",
      "Epoch 76/100\n",
      "1672/1672 [==============================] - 0s 77us/step - loss: 0.6381 - acc: 0.6089 - val_loss: 0.6538 - val_acc: 0.6143\n",
      "Epoch 77/100\n",
      "1672/1672 [==============================] - 0s 116us/step - loss: 0.6390 - acc: 0.6364 - val_loss: 0.5715 - val_acc: 0.7163\n",
      "Epoch 78/100\n",
      "1672/1672 [==============================] - 0s 76us/step - loss: 0.6373 - acc: 0.6100 - val_loss: 0.6509 - val_acc: 0.6198\n",
      "Epoch 79/100\n",
      "1672/1672 [==============================] - 0s 74us/step - loss: 0.6373 - acc: 0.6394 - val_loss: 0.5723 - val_acc: 0.7273\n",
      "Epoch 80/100\n",
      "1672/1672 [==============================] - 0s 74us/step - loss: 0.6336 - acc: 0.6196 - val_loss: 0.6476 - val_acc: 0.6226\n",
      "Epoch 81/100\n",
      "1672/1672 [==============================] - 0s 79us/step - loss: 0.6347 - acc: 0.6411 - val_loss: 0.5706 - val_acc: 0.7245\n",
      "Epoch 82/100\n",
      "1672/1672 [==============================] - 0s 109us/step - loss: 0.6340 - acc: 0.6190 - val_loss: 0.6509 - val_acc: 0.6198\n",
      "Epoch 83/100\n",
      "1672/1672 [==============================] - 0s 117us/step - loss: 0.6355 - acc: 0.6352 - val_loss: 0.5695 - val_acc: 0.7218\n",
      "Epoch 84/100\n",
      "1672/1672 [==============================] - 0s 77us/step - loss: 0.6356 - acc: 0.6118 - val_loss: 0.6521 - val_acc: 0.6143\n",
      "Epoch 85/100\n",
      "1672/1672 [==============================] - 0s 79us/step - loss: 0.6355 - acc: 0.6364 - val_loss: 0.5697 - val_acc: 0.7273\n",
      "Epoch 86/100\n",
      "1672/1672 [==============================] - 0s 75us/step - loss: 0.6326 - acc: 0.6226 - val_loss: 0.6463 - val_acc: 0.6226\n",
      "Epoch 87/100\n",
      "1672/1672 [==============================] - 0s 77us/step - loss: 0.6323 - acc: 0.6453 - val_loss: 0.5696 - val_acc: 0.7300\n",
      "Epoch 88/100\n",
      "1672/1672 [==============================] - 0s 75us/step - loss: 0.6306 - acc: 0.6256 - val_loss: 0.6461 - val_acc: 0.6226\n",
      "Epoch 89/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6313 - acc: 0.6423 - val_loss: 0.5687 - val_acc: 0.7273\n",
      "Epoch 90/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6309 - acc: 0.6268 - val_loss: 0.6466 - val_acc: 0.6198\n",
      "Epoch 91/100\n",
      "1672/1672 [==============================] - 0s 80us/step - loss: 0.6309 - acc: 0.6447 - val_loss: 0.5687 - val_acc: 0.7273\n",
      "Epoch 92/100\n",
      "1672/1672 [==============================] - 0s 77us/step - loss: 0.6289 - acc: 0.6268 - val_loss: 0.6441 - val_acc: 0.6336\n",
      "Epoch 93/100\n",
      "1672/1672 [==============================] - 0s 75us/step - loss: 0.6291 - acc: 0.6471 - val_loss: 0.5682 - val_acc: 0.7273\n",
      "Epoch 94/100\n",
      "1672/1672 [==============================] - 0s 78us/step - loss: 0.6278 - acc: 0.6286 - val_loss: 0.6437 - val_acc: 0.6336\n",
      "Epoch 95/100\n",
      "1672/1672 [==============================] - 0s 102us/step - loss: 0.6282 - acc: 0.6477 - val_loss: 0.5672 - val_acc: 0.7245\n",
      "Epoch 96/100\n",
      "1672/1672 [==============================] - 0s 84us/step - loss: 0.6285 - acc: 0.6268 - val_loss: 0.6455 - val_acc: 0.6281\n",
      "Epoch 97/100\n",
      "1672/1672 [==============================] - 0s 87us/step - loss: 0.6284 - acc: 0.6477 - val_loss: 0.5667 - val_acc: 0.7245\n",
      "Epoch 98/100\n",
      "1672/1672 [==============================] - 0s 72us/step - loss: 0.6276 - acc: 0.6286 - val_loss: 0.6454 - val_acc: 0.6253\n",
      "Epoch 99/100\n",
      "1672/1672 [==============================] - 0s 73us/step - loss: 0.6277 - acc: 0.6495 - val_loss: 0.5666 - val_acc: 0.7273\n",
      "Epoch 100/100\n",
      "1672/1672 [==============================] - 0s 108us/step - loss: 0.6260 - acc: 0.6310 - val_loss: 0.6460 - val_acc: 0.6253\n"
     ]
    }
   ],
   "source": [
    "#compile our model and fit it to our training data\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history1 = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=100,\n",
    "                    batch_size=1672,\n",
    "                    validation_data=(val_img, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672/1672 [==============================] - 0s 93us/step\n"
     ]
    }
   ],
   "source": [
    "#examine our evaluation metrics for how our model on the training set\n",
    "results_train = model.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 0s 286us/step\n"
     ]
    }
   ],
   "source": [
    "#examine our evaluation metrics for how our model performed on the test set \n",
    "results_test = model.evaluate(test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6271645007521341, 0.6501196172248804]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the [loss, and accuracy] of our training data\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6459931181027339, 0.5974358971302326]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the [loss and accuracy] of our test data\n",
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ConvNet: Initial Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import earlystopping from keras and set a variable called earlystopping that ends our run model if our validation loss doesnt increase by a certain amount in a number of epochs\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1673 images belonging to 2 classes.\n",
      "Found 390 images belonging to 2 classes.\n",
      "Found 363 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# get all the data in the directory split/test (271 images), and reshape them\n",
    "# get all the data in the directory split/train (2477 images), and reshape them\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_dir, \n",
    "        target_size=(64, 64), batch_size= batch_size_train)\n",
    "\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_dir, \n",
    "        target_size=(64, 64), batch_size = batch_size_test)   \n",
    "\n",
    "# get all the data in the directory split/validation (257 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_dir, \n",
    "        target_size=(64, 64), batch_size = batch_size_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate our cnn_model with conv layers and maxpooling and a flatten layer as our last hidden layer \n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape = (64, 64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1672 samples, validate on 363 samples\n",
      "Epoch 1/75\n",
      "1672/1672 [==============================] - 10s 6ms/step - loss: 0.6873 - acc: 0.5580 - val_loss: 0.6418 - val_acc: 0.7080\n",
      "Epoch 2/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.6781 - acc: 0.5843 - val_loss: 0.6324 - val_acc: 0.7107\n",
      "Epoch 3/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.6695 - acc: 0.5993 - val_loss: 0.7973 - val_acc: 0.2920\n",
      "Epoch 4/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.6616 - acc: 0.6142 - val_loss: 0.8615 - val_acc: 0.2920\n",
      "Epoch 5/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.6570 - acc: 0.6489 - val_loss: 0.6489 - val_acc: 0.6887\n",
      "Epoch 6/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.6464 - acc: 0.6501 - val_loss: 0.5713 - val_acc: 0.7107\n",
      "Epoch 7/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.6246 - acc: 0.6651 - val_loss: 0.7576 - val_acc: 0.3802\n",
      "Epoch 8/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.6272 - acc: 0.6543 - val_loss: 0.5390 - val_acc: 0.7631\n",
      "Epoch 9/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.6179 - acc: 0.6591 - val_loss: 0.5981 - val_acc: 0.7107\n",
      "Epoch 10/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5944 - acc: 0.7033 - val_loss: 0.5225 - val_acc: 0.7713\n",
      "Epoch 11/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5956 - acc: 0.6818 - val_loss: 0.5971 - val_acc: 0.7052\n",
      "Epoch 12/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5907 - acc: 0.7004 - val_loss: 0.5283 - val_acc: 0.7713\n",
      "Epoch 13/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5730 - acc: 0.7010 - val_loss: 0.6574 - val_acc: 0.6226\n",
      "Epoch 14/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5544 - acc: 0.7297 - val_loss: 0.4977 - val_acc: 0.7851\n",
      "Epoch 15/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5631 - acc: 0.7129 - val_loss: 0.5144 - val_acc: 0.7631\n",
      "Epoch 16/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5540 - acc: 0.7189 - val_loss: 0.5487 - val_acc: 0.7410\n",
      "Epoch 17/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5527 - acc: 0.7225 - val_loss: 0.6591 - val_acc: 0.6309\n",
      "Epoch 18/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5553 - acc: 0.7207 - val_loss: 0.5561 - val_acc: 0.7163\n",
      "Epoch 19/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5360 - acc: 0.7380 - val_loss: 0.6402 - val_acc: 0.6419\n",
      "Epoch 20/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5428 - acc: 0.7428 - val_loss: 0.5496 - val_acc: 0.7300\n",
      "Epoch 21/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5324 - acc: 0.7512 - val_loss: 0.4755 - val_acc: 0.7961\n",
      "Epoch 22/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5253 - acc: 0.7482 - val_loss: 0.4864 - val_acc: 0.7934\n",
      "Epoch 23/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5307 - acc: 0.7404 - val_loss: 0.8141 - val_acc: 0.5207\n",
      "Epoch 24/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5141 - acc: 0.7500 - val_loss: 0.5198 - val_acc: 0.7383\n",
      "Epoch 25/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5176 - acc: 0.7500 - val_loss: 0.5351 - val_acc: 0.7383\n",
      "Epoch 26/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5193 - acc: 0.7404 - val_loss: 0.4685 - val_acc: 0.7934\n",
      "Epoch 27/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5024 - acc: 0.7644 - val_loss: 0.5017 - val_acc: 0.7603\n",
      "Epoch 28/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.4959 - acc: 0.7644 - val_loss: 0.4709 - val_acc: 0.8072\n",
      "Epoch 29/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.4923 - acc: 0.7715 - val_loss: 0.6945 - val_acc: 0.6281\n",
      "Epoch 30/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.5031 - acc: 0.7494 - val_loss: 0.4996 - val_acc: 0.7521\n",
      "Epoch 31/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.4948 - acc: 0.7626 - val_loss: 0.5797 - val_acc: 0.7273\n",
      "Epoch 32/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.4966 - acc: 0.7673 - val_loss: 0.6270 - val_acc: 0.6667\n",
      "Epoch 33/75\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 0.4858 - acc: 0.7733 - val_loss: 0.6658 - val_acc: 0.6446\n"
     ]
    }
   ],
   "source": [
    "#fit our cnn to the training set \n",
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=75,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y), callbacks = [early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to drive\n"
     ]
    }
   ],
   "source": [
    "#save my model to drive only need to do this once\n",
    "model_json = model.to_json()\n",
    "with open(\"model_cnn_one.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_cnn_one.h5\")\n",
    "print(\"Saved model to drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluating Initial CNN Model__\n",
    "\n",
    "\n",
    "Not sure if our model is actually able to determine clean or dirty rooms or if there is just a common feature or patern outside of the desired image content for our training set data that results in our model overfitting. So want to check how it is performing on each one of our datasets where our validation and test sets for our dirty images have been sorted, filtered and made to look exactly like our clean image photos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 1s 3ms/step\n",
      "1672/1672 [==============================] - 4s 2ms/step\n",
      "363/363 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#examine our evaluation metrics for how our model performed on the test set \n",
    "results_one_test = model.evaluate(test_images, test_y)\n",
    "\n",
    "#and our training data\n",
    "results_one_train = model.evaluate(train_images, train_y)\n",
    "\n",
    "#do the same for our validation images and targets\n",
    "results_one_validate = model.evaluate(val_images, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the [loss, and accuracy] of our training data\n",
    "model_one_acc_train = results_one_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the results for our validation set \n",
    "model_one_acc_val = results_one_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the [loss and accuracy] of our test data\n",
    "model_one_acc_test = results_one_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Save our Model Weights and Probabilities__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to using our model to predict a clean and dirty room we also thought it would be useful to have our final output layer use a softmax function instead of a sigmoid function so each image could return us a predicted probability, which we can then use as a \"cleanliness\" metric. Using keras' predict_proba method we can examine if this might be worth our time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to try and use this model to output a predictive value \n",
    "model_proba_train = model.predict_proba(train_images)\n",
    "\n",
    "#examining the probability as a metric for how dirty or clean a room will be \n",
    "model_proba_test = model.predict_proba(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05072623],\n",
       "       [0.14476797],\n",
       "       [0.5585816 ],\n",
       "       [0.41537106],\n",
       "       [0.16759878],\n",
       "       [0.08846781],\n",
       "       [0.5759965 ],\n",
       "       [0.17328486],\n",
       "       [0.6138184 ],\n",
       "       [0.76122534]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine our probabilities that are being fed into the output layer and then converted to a 0 or 1 using the sigmoid function\n",
    "model_proba_test[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1A450A0E48>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_to_img(test_images[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__VGG16 Model: Transfer Learning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported VGG16 as our base model with weights set to \"imagenet\" and used transfer learning techniques to construct a network with 16 pretrained layers. We then added and number of our own dense and dropout layers that performed well for our initial CNN model. Our output layer we left as a sigmoid activation using binary crossentropy to calculate our loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary model for transfer learning\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Dropout\n",
    "#instantiate our base_model with VGG16 after removing an output layer and altering the input shape\n",
    "base_model = VGG16(include_top = False, weights = 'imagenet', input_shape = (64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/AlexGaujean/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# instantiate our new model and add a layer to the pretrained base_model\n",
    "model = models.Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Dense(512, activation ='relu')) #, data_format = 'channels_last')\n",
    "model.add(Dropout(0.4)) \n",
    "model.add(Dense(64, activation ='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile our model using binary_crossentropy as the loss parameter\n",
    "model.compile(loss ='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that we do not retrain the first 16 pretrained layers of our model and only train the following layers\n",
    "for layer in model.layers[:16]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[16:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AlexGaujean/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1679 samples, validate on 366 samples\n",
      "Epoch 1/75\n",
      " 320/1679 [====>.........................] - ETA: 3:07 - loss: 0.6858 - acc: 0.6031"
     ]
    }
   ],
   "source": [
    "#fit our train images and train labels to our ResNet transfer learning model\n",
    "history_3 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=75,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y), callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our weights and model to our folder\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_weights_vgg.h5\")\n",
    "print(\"Saved model to drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine our evaluation metrics for how our model performed on the test set \n",
    "results_vgg_test = model.evaluate(test_images, test_y)\n",
    "\n",
    "#and our training data\n",
    "results_vgg_train = model.evaluate(train_images, train_y)\n",
    "\n",
    "#do the same for our validation images and targets\n",
    "results_vgg_validate = model.evaluate(val_images, val_y)\n",
    "\n",
    "## print the [loss, and accuracy] of our training data\n",
    "model_vgg_acc_train = results_train\n",
    "\n",
    "# check the results for our validation set \n",
    "model_vgg_acc_val = results_validate\n",
    "\n",
    "#print the [loss and accuracy] of our test data\n",
    "model_vgg_acc_test = results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locally save our weights and model to our folder\n",
    "model_vgg_json = model.to_json()\n",
    "model_vgg_weights = model.get_weights()\n",
    "model_vgg_inputs = model.inputs\n",
    "model_vgg_outputs = model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate our model using keras.summary() method\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resnet Model: Transfer Learning 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries for ResNet\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.preprocessing import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries for ResNet\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, MaxPooling2D\n",
    "\n",
    "\n",
    "\n",
    "#instantiate a base_model with our ResNet layer\n",
    "base_model = ResNet50(weights='imagenet', include_top = False)\n",
    "\n",
    "\n",
    "\n",
    "#setup our model with the ResNet as the base and add a few more hidden layers\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(base_model) \n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(1024,  activation='relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "#compile our model using binary_crossentropy as the loss parameter\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "\n",
    "#make sure that we do not retrain the first 50 pretrained layers of our model\n",
    "for layer in model.layers[:50]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "    \n",
    "#fit our training images and training labels to our model\n",
    "history_3 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=75,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y), callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine our evaluation metrics for how our model performed on the test set \n",
    "results_res_test = model.evaluate(test_images, test_y)\n",
    "\n",
    "#and our training data\n",
    "results_res_train = model.evaluate(train_images, train_y)\n",
    "\n",
    "#do the same for our validation images and targets\n",
    "results_res_validate = model.evaluate(val_images, val_y)\n",
    "\n",
    "## print the [loss, and accuracy] of our training data\n",
    "model_res_acc_train = results_train\n",
    "\n",
    "# check the results for our validation set \n",
    "model_res_acc_val = results_validate\n",
    "\n",
    "#print the [loss and accuracy] of our test data\n",
    "model_res_acc_test = results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locally save our weights and model\n",
    "model_res_json = model.to_json()\n",
    "model_res_weights = model.get_weights()\n",
    "model_res_inputs = model.inputs\n",
    "model_res_outputs = model.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing our Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to visualize our images within the intermediate layers for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries \n",
    "from keras import models\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our locally saved variable of our model outputs [list of tensors] to select an image tensor\n",
    "img_tensor = model_res_outputs[150]\n",
    "\n",
    "# Extract model layer outputs\n",
    "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
    "\n",
    "# Rather then a model with a single output, we are going to make a model to display the feature maps\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_vgg_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-d6430065f5d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_vgg_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_vgg_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "#use our locally saved variable of our model outputs [list of tensors] to select an image tensor\n",
    "img_tensor = model_vgg_outputs[150]\n",
    "# Extract model layer outputs\n",
    "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
    "\n",
    "# Rather then a model with a single output, we are going to make a model to display the feature maps\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-b9f650a693cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Rather then a model with a single output, we are going to make a model to display the feature maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mactivation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract model layer outputs\n",
    "layer_outputs = [layer.output for layer in model.layers[:10]]\n",
    "\n",
    "# Rather then a model with a single output, we are going to make a model to display the feature maps\n",
    "activation_model = models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "activations = activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'activations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-c32d538a8ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcur_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticks_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottom'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'activations' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2,4, figsize=(12,8))\n",
    "\n",
    "layer_names = []\n",
    "for layer in model.layers[:8]:\n",
    "    layer_names.append(layer.name)\n",
    "    \n",
    "for i in range(8):\n",
    "    row = i//4\n",
    "    column = i%4\n",
    "    ax = axes[row, column]\n",
    "    cur_layer = activations[i]\n",
    "    ax.matshow(cur_layer[0, :, :, 29], cmap='viridis')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(layer_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary that will be used to construct our barchart that will contain accuracy metrics for our train and test set for each model that we ran\n",
    "auc_dict = {'Model': ['Baseline','Baseline', 'Simple_ConvNet', 'Simple_ConvNet', 'VGG16', 'VGG16','ResNet', 'ResNet'], \n",
    "            'Accuracy': [.6337, .7513, .7784, .7795, .9988, .9051, .5455, .6948], \n",
    "            'type':['Train','Test','Train','Test','Train','Test','Train','Test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xb88923ef0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot that shows the different accuracy scores for each of our models, train and test set. \n",
    "plt.figure(figsize=(12,8))\n",
    "accuracy = pd.DataFrame(auc_dict, columns = auc_dict.keys())\n",
    "ax = sns.barplot(x=\"Model\", y=\"Accuracy\", hue=\"type\", data=accuracy, color='red')\n",
    "plt.title('Comparison of Accuracy by Model',fontsize = 15)\n",
    "plt.legend(loc=\"upper right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
